{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Mockafka python lib","text":""},{"location":"#getting-start","title":"Getting Start","text":""},{"location":"#installing-via-pip","title":"Installing via pip","text":"<pre><code>pip install mockafka-py\n</code></pre>"},{"location":"#usage","title":"Usage","text":""},{"location":"#using-classes-like-confluent-kafka","title":"Using classes like confluent-kafka","text":"<pre><code>from mockafka import FakeProducer, FakeConsumer, FakeAdminClientImpl\nfrom mockafka.admin_client import NewTopic\nfrom random import randint\n\n# Create topic\nadmin = FakeAdminClientImpl()\nadmin.create_topics([\n    NewTopic(topic='test', num_partitions=5)\n])\n\n# Produce messages\nproducer = FakeProducer()\nfor i in range(0, 10):\n    producer.produce(\n        topic='test',\n        key=f'test_key{i}',\n        value=f'test_value{i}',\n        partition=randint(0, 4)\n    )\n\n# Subscribe consumer\nconsumer = FakeConsumer()\nconsumer.subscribe(topics=['test'])\n\n# Consume messages\nwhile True:\n    message = consumer.poll()\n    print(message)\n    consumer.commit()\n\n    if message is None:\n        break\n</code></pre> <p>Output: <pre><code>\"\"\"\n&lt;mockafka.message.Message object at 0x7fe84b4c3310&gt;\n&lt;mockafka.message.Message object at 0x7fe84b4c3370&gt;\n&lt;mockafka.message.Message object at 0x7fe84b4c33a0&gt;\n&lt;mockafka.message.Message object at 0x7fe84b4c33d0&gt;\n&lt;mockafka.message.Message object at 0x7fe84b4c3430&gt;\n&lt;mockafka.message.Message object at 0x7fe84b4c32e0&gt;\n&lt;mockafka.message.Message object at 0x7fe84b4c31f0&gt;\n&lt;mockafka.message.Message object at 0x7fe84b4c32b0&gt;\n&lt;mockafka.message.Message object at 0x7fe84b4c3400&gt;\n&lt;mockafka.message.Message object at 0x7fe84b4c3340&gt;\nNone\n\"\"\"\n</code></pre></p>"},{"location":"async-decorators/","title":"fake async decorators","text":""},{"location":"async-decorators/#aconsume-decorator","title":"<code>@aconsume</code> Decorator","text":"<p>This decorator is designed for simulating asynchronous message consumption using a <code>FakeAIOKafkaConsumer</code>. It subscribes to specified topics and consumes messages in a loop. For each message consumed, it calls the decorated function with the message as a keyword argument. After consuming all available messages, it calls the decorated function again without the message argument.</p>"},{"location":"async-decorators/#parameters","title":"Parameters:","text":"<ul> <li><code>topics (list[str])</code>: List of topic names to subscribe to.</li> <li><code>auto_commit (bool)</code>: Whether to automatically commit offsets after consuming messages. Default is True.</li> </ul>"},{"location":"async-decorators/#example-usage","title":"Example Usage:","text":"<pre><code>from mockafka import aconsume\n\n@aconsume(topics=['test'], auto_commit=False)\nasync def process_message(message):\n    # message processing logic\n</code></pre>"},{"location":"async-decorators/#aproduce-decorator","title":"<code>@aproduce</code> Decorator","text":"<p>This decorator is for simulating message production using a <code>FakeAIOKafkaProducer</code>. It creates a <code>FakeAIOKafkaProducer</code> instance and calls <code>send()</code> to produce a message with the provided parameters. Then, it calls the decorated function.</p>"},{"location":"async-decorators/#parameters_1","title":"Parameters:","text":"<ul> <li><code>**decorator_args</code>: Arguments for producing the message, including:</li> <li><code>topic (str)</code>: Topic to produce to.</li> <li><code>value (str)</code>: Message value.</li> <li><code>key (str)</code>: Message key.</li> <li><code>headers (dict)</code>: Message headers.</li> <li><code>partition (int)</code>: Topic partition to produce to.</li> </ul>"},{"location":"async-decorators/#example-usage_1","title":"Example Usage:","text":"<pre><code>from mockafka import aproduce\n\n@aproduce(topic='test', value='foo')\nasync def produce_message():\n    # test logic here\n</code></pre>"},{"location":"async-decorators/#asetup_kafka-decorator","title":"<code>@asetup_kafka</code> Decorator","text":"<p>This decorator is for setting up mock Kafka topics using a <code>FakeAIOKafkaAdminClient</code>. It takes a list of topic configurations, each containing the topic name and partition count, and an option to clean existing topics first. It creates the specified topics using a <code>FakeAIOKafkaAdminClient</code>.</p>"},{"location":"async-decorators/#parameters_2","title":"Parameters:","text":"<ul> <li><code>topics (list[dict]):</code> List of topic configurations, each containing:</li> <li><code>topic (str)</code>: Topic name.</li> <li><code>partition (int)</code>: Partition count.</li> <li><code>clean (bool):</code> Whether to clean existing topics first. Default is False.</li> </ul>"},{"location":"async-decorators/#example-usage_2","title":"Example Usage:","text":"<pre><code>from mockafka import asetup_kafka\n\n@asetup_kafka(topics=[{'topic': 'test', 'partition': 1}])\nasync def test_function():\n    # test logic\n</code></pre>"},{"location":"async-fake-aiokafka-admin-client/","title":"fake aiokafka admin client","text":""},{"location":"async-fake-aiokafka-admin-client/#fakeaiokafkaadmin-class","title":"FakeAIOKafkaAdmin Class","text":""},{"location":"async-fake-aiokafka-admin-client/#description","title":"Description","text":"<p>The <code>FakeAIOKafkaAdmin</code> class is a mock implementation of aiokafka's <code>AIOKafkaAdminClient</code>. It allows mocking Kafka administration operations for testing purposes.</p>"},{"location":"async-fake-aiokafka-admin-client/#parameters","title":"Parameters","text":"<ul> <li>clean (bool): Whether to clean/reset the underlying <code>KafkaStore</code> on init. Default is False.</li> </ul>"},{"location":"async-fake-aiokafka-admin-client/#methods","title":"Methods","text":""},{"location":"async-fake-aiokafka-admin-client/#__init__self-clean-bool-false-args-kwargs","title":"<code>__init__(self, clean: bool = False, *args, **kwargs)</code>","text":"<ul> <li>Description: Initializes the <code>FakeAIOKafkaAdmin</code>.</li> <li>Parameters:</li> <li><code>clean (bool):</code> Whether to clean/reset the underlying <code>KafkaStore</code> on init. Default is False.</li> <li><code>*args, **kwargs</code>: Additional arguments.</li> </ul>"},{"location":"async-fake-aiokafka-admin-client/#closeself","title":"<code>close(self)</code>","text":"<ul> <li>Description: Closes the admin client.</li> </ul>"},{"location":"async-fake-aiokafka-admin-client/#startself","title":"<code>start(self)</code>","text":"<ul> <li>Description: Starts the admin client.</li> </ul>"},{"location":"async-fake-aiokafka-admin-client/#_create_topicself-topic-newtopic-none","title":"<code>_create_topic(self, topic: NewTopic) -&gt; None</code>","text":"<ul> <li>Description: Creates a topic in the underlying <code>KafkaStore</code>.</li> <li>Parameters:</li> <li><code>topic (NewTopic):</code> NewTopic object containing name and num_partitions.</li> </ul>"},{"location":"async-fake-aiokafka-admin-client/#_remove_topicself-topic-str","title":"<code>_remove_topic(self, topic: str)</code>","text":"<ul> <li>Description: Deletes a topic from the underlying <code>KafkaStore</code> by name.</li> <li>Parameters:</li> <li><code>topic (str):</code> Name of the topic to delete.</li> </ul>"},{"location":"async-fake-aiokafka-admin-client/#create_topicsself-new_topics-listnewtopic-args-kwargs","title":"<code>create_topics(self, new_topics: list[NewTopic], *args, **kwargs)</code>","text":"<ul> <li>Description: Creates multiple topics from a list of <code>NewTopic</code> objects. Calls <code>_create_topic()</code> for each one.</li> <li>Parameters:</li> <li><code>new_topics (list[NewTopic]):</code> List of <code>NewTopic</code> objects.</li> </ul>"},{"location":"async-fake-aiokafka-admin-client/#delete_topicsself-topics-liststr-kwargs-none","title":"<code>delete_topics(self, topics: list[str], **kwargs) -&gt; None</code>","text":"<ul> <li>Description: Deletes multiple topics by name from a list of strings. Calls <code>_remove_topic()</code> for each one.</li> <li>Parameters:</li> <li><code>topics (list[str]):</code> List of topic names to delete.</li> </ul>"},{"location":"async-fake-aiokafka-admin-client/#_create_partitionself-topic-str-partition_count-int","title":"<code>_create_partition(self, topic: str, partition_count: int)</code>","text":"<ul> <li>Description: Adds partitions to a topic in <code>KafkaStore</code>.</li> <li>Parameters:</li> <li><code>topic (str):</code> Name of the topic.</li> <li><code>partition_count (int):</code> Number of partitions to add.</li> </ul>"},{"location":"async-fake-aiokafka-admin-client/#create_partitionsself-topic_partitions-dictstr-newpartitions-args-kwargs","title":"<code>create_partitions(self, topic_partitions: Dict[str, NewPartitions], *args, **kwargs)</code>","text":"<ul> <li>Description: Adds partitions to multiple topics from a dictionary mapping topic name to <code>NewPartitions</code> object containing <code>total_count</code>. Calls <code>_create_partition()</code> for each topic.</li> <li>Parameters:</li> <li><code>topic_partitions (Dict[str, NewPartitions]):</code> Dictionary mapping topic name to <code>NewPartitions</code> object.</li> </ul>"},{"location":"async-fake-aiokafka-admin-client/#example-usage","title":"Example Usage","text":"<pre><code>from aiokafka import NewTopic, NewPartitions\nfrom mockafka.aiokafka import FakeAIOKafkaAdmin\n\n# Create an instance of FakeAIOKafkaAdmin\nfake_admin = FakeAIOKafkaAdmin()\n\n# Define new topics\nnew_topics = [NewTopic(name='topic1', num_partitions=3), NewTopic(name='topic2', num_partitions=5)]\n\n# Create topics\nawait fake_admin.create_topics(new_topics=new_topics)\n\n# Define additional partitions for topics\ntopic_partitions = {'topic1': NewPartitions(total_count=5), 'topic2': NewPartitions(total_count=7)}\n\n# Add partitions to topics\nawait fake_admin.create_partitions(topic_partitions=topic_partitions)\n</code></pre>"},{"location":"async-fake-aiokafka-consumer/","title":"fake aiokafka consumer","text":""},{"location":"async-fake-aiokafka-consumer/#fakeaiokafkaconsumer-class","title":"FakeAIOKafkaConsumer Class","text":""},{"location":"async-fake-aiokafka-consumer/#description","title":"Description","text":"<p>The <code>FakeAIOKafkaConsumer</code> class is a mock implementation of aiokafka's AIOKafkaConsumer. It allows mocking a Kafka consumer for testing purposes.</p>"},{"location":"async-fake-aiokafka-consumer/#parameters","title":"Parameters","text":"<ul> <li>args, kwargs: Passed to superclass init, not used here.</li> </ul>"},{"location":"async-fake-aiokafka-consumer/#attributes","title":"Attributes","text":"<ul> <li>kafka: A <code>KafkaStore</code> instance for underlying storage.</li> <li>consumer_store (dict): Tracks consumption progress per topic/partition.</li> <li>subscribed_topic (list): List of subscribed topic names.</li> </ul>"},{"location":"async-fake-aiokafka-consumer/#methods","title":"Methods","text":""},{"location":"async-fake-aiokafka-consumer/#__init__self-args-kwargs","title":"<code>__init__(self, *args, **kwargs)</code>","text":"<ul> <li>Description: Initializes the <code>FakeAIOKafkaConsumer</code>.</li> <li>Parameters:</li> <li><code>args, kwargs</code>: Passed to superclass init, not used here.</li> </ul>"},{"location":"async-fake-aiokafka-consumer/#startself","title":"<code>start(self)</code>","text":"<ul> <li>Description: Resets the internal state.</li> </ul>"},{"location":"async-fake-aiokafka-consumer/#stopself","title":"<code>stop(self)</code>","text":"<ul> <li>Description: Resets the internal state.</li> </ul>"},{"location":"async-fake-aiokafka-consumer/#commitself","title":"<code>commit(self)</code>","text":"<ul> <li>Description: Commits offsets to <code>KafkaStore</code> by updating <code>first_offset</code>.</li> </ul>"},{"location":"async-fake-aiokafka-consumer/#topicsself","title":"<code>topics(self)</code>","text":"<ul> <li>Description: Gets subscribed topics.</li> </ul>"},{"location":"async-fake-aiokafka-consumer/#subscribeself-topics-liststr","title":"<code>subscribe(self, topics: list[str])</code>","text":"<ul> <li>Description: Subscribes to topics by name.</li> </ul>"},{"location":"async-fake-aiokafka-consumer/#subscriptionself-liststr","title":"<code>subscription(self) -&gt; list[str]</code>","text":"<ul> <li>Description: Gets subscribed topics.</li> </ul>"},{"location":"async-fake-aiokafka-consumer/#unsubscribeself","title":"<code>unsubscribe(self)</code>","text":"<ul> <li>Description: Resets subscribed topics.</li> </ul>"},{"location":"async-fake-aiokafka-consumer/#_get_keyself-topic-partition-str","title":"<code>_get_key(self, topic, partition) -&gt; str</code>","text":"<ul> <li>Description: Generates <code>consumer_store</code> lookup key from topic/partition.</li> </ul>"},{"location":"async-fake-aiokafka-consumer/#getoneself","title":"<code>getone(self)</code>","text":"<ul> <li>Description: Gets the next available message from subscribed topics. Updates <code>consumer_store</code> as messages are consumed.</li> </ul>"},{"location":"async-fake-aiokafka-consumer/#getmanyself","title":"<code>getmany(self)</code>","text":"<ul> <li>Description: Currently just calls <code>getone()</code>.</li> </ul>"},{"location":"async-fake-aiokafka-consumer/#example-usage","title":"Example Usage","text":"<pre><code>from mockafka.aiokafka import FakeAIOKafkaConsumer\n\n# Create an instance of FakeAIOKafkaConsumer\nfake_consumer = FakeAIOKafkaConsumer()\n\n# Subscribe to topics\nfake_consumer.subscribe(topics=['sample_topic1', 'sample_topic2'])\n\n# start consumer \nawait fake_consumer.start()\n\n# Get one message\nmessage = await fake_consumer.getone()\n</code></pre>"},{"location":"async-fake-aiokafka-produce/","title":"fake aiokafka producer","text":""},{"location":"async-fake-aiokafka-produce/#fakeaiokafkaproducer-class","title":"FakeAIOKafkaProducer Class","text":""},{"location":"async-fake-aiokafka-produce/#description","title":"Description","text":"<p>The <code>FakeAIOKafkaProducer</code> class is a mock implementation of aiokafka's AIOKafkaProducer. It allows mocking a Kafka producer for testing purposes.</p>"},{"location":"async-fake-aiokafka-produce/#parameters","title":"Parameters","text":"<ul> <li>args, kwargs: Passed to superclass init, not used here.</li> </ul>"},{"location":"async-fake-aiokafka-produce/#attributes","title":"Attributes","text":"<ul> <li>kafka: A <code>KafkaStore</code> instance for underlying storage.</li> </ul>"},{"location":"async-fake-aiokafka-produce/#methods","title":"Methods","text":""},{"location":"async-fake-aiokafka-produce/#__init__self-args-kwargs","title":"<code>__init__(self, *args, **kwargs)</code>","text":"<ul> <li>Description: Initializes the <code>FakeAIOKafkaProducer</code>.</li> <li>Parameters:</li> <li><code>args, kwargs</code>: Passed to superclass init, not used here.</li> </ul>"},{"location":"async-fake-aiokafka-produce/#_produceself-topic-valuenone-args-kwargs","title":"<code>_produce(self, topic, value=None, *args, **kwargs)</code>","text":"<ul> <li>Description: Create a <code>Message</code> and produce it to <code>KafkaStore</code>.</li> <li>Parameters:</li> <li><code>topic</code>: Topic to produce the message to.</li> <li><code>value</code>: Message value.</li> <li><code>args</code>: Additional arguments.</li> <li><code>kwargs</code>: Additional keyword arguments, including the partition for the message.</li> </ul>"},{"location":"async-fake-aiokafka-produce/#startself","title":"<code>start(self)</code>","text":"<ul> <li>Description: No-operation.</li> </ul>"},{"location":"async-fake-aiokafka-produce/#stopself","title":"<code>stop(self)</code>","text":"<ul> <li>Description: No-operation.</li> </ul>"},{"location":"async-fake-aiokafka-produce/#sendself-args-kwargs","title":"<code>send(self, *args, **kwargs)</code>","text":"<ul> <li>Description: Calls <code>_produce()</code> with keyword arguments.</li> <li>Parameters:</li> <li><code>args, kwargs</code>: Arguments and keyword arguments passed to <code>_produce()</code>.</li> </ul>"},{"location":"async-fake-aiokafka-produce/#send_and_waitself-args-kwargs","title":"<code>send_and_wait(self, *args, **kwargs)</code>","text":"<ul> <li>Description: Calls <code>send()</code>.</li> <li>Parameters:</li> <li><code>args, kwargs</code>: Arguments and keyword arguments passed to <code>send()</code>.</li> </ul>"},{"location":"async-fake-aiokafka-produce/#example-usage","title":"Example Usage","text":"<pre><code>from mockafka.aiokafka import FakeAIOKafkaProducer\n\n# Create an instance of FakeAIOKafkaProducer\nfake_producer = FakeAIOKafkaProducer()\n\n# Produce a message\nawait fake_producer.send(topic='sample_topic', value='Hello, Kafka!', partition=0)\n</code></pre>"},{"location":"decorators/","title":"decorators","text":""},{"location":"decorators/#decorators-documentation","title":"Decorators Documentation","text":""},{"location":"decorators/#setup_kafka-decorator","title":"<code>@setup_kafka</code> Decorator","text":"<p>This decorator is designed for setting up Mockafka with specified topics using a <code>FakeAdminClient</code>. It allows you to define topics and their partitions and choose whether to start with a clean Kafka (remove existing topics) or not.</p>"},{"location":"decorators/#parameters","title":"Parameters:","text":"<ul> <li><code>topics (list[dict[str, str]])</code>: A list of dictionaries containing topic details. Each dictionary should have the keys 'topic' and 'partition'.</li> <li><code>clean (bool)</code>: Option to have a clean Kafka (remove existing topics) or not.</li> </ul>"},{"location":"decorators/#example-usage","title":"Example Usage:","text":"<pre><code>from mockafka import setup_kafka\n\n@setup_kafka(topics=[{'topic': 'test_topic', 'partition': 5}], clean=True)\n\ndef test_function():\n    # Your test logic here\n    pass\n</code></pre>"},{"location":"decorators/#produce-decorator","title":"<code>@produce</code> Decorator","text":"<p>This decorator simulates message production using a <code>FakeProducer</code>. It allows you to specify the topic, value, key, headers, and partition of the produced message.</p>"},{"location":"decorators/#parameters_1","title":"Parameters:","text":"<ul> <li><code>topic (str)</code>: The topic to produce the message.</li> <li><code>value (str)</code>: The value of the message.</li> <li><code>key (str)</code>: The key of the message.</li> <li><code>headers (str)</code>: The headers of the message.</li> <li><code>partition (str)</code>: The partition of the topic.</li> </ul>"},{"location":"decorators/#example-usage_1","title":"Example Usage:","text":"<pre><code>from mockafka import produce\n\n@produce(topic='test_topic', value='test_value', key='test_key', headers=None, partition=0)\ndef test_function():\n    # Your test logic here\n    pass\n</code></pre>"},{"location":"decorators/#consume-decorator","title":"<code>@consume</code> Decorator","text":"<p>This decorator simulates message consumption using a <code>FakeConsumer</code>. It allows you to subscribe to specified topics and provides the consumed message to the decorated function.</p>"},{"location":"decorators/#parameters_2","title":"Parameters:","text":"<ul> <li><code>topics (list[str])</code>: A list of topics to subscribe to.</li> <li><code>auto_commit (bool)</code>: Whether to automatically commit offsets after consuming messages.</li> </ul>"},{"location":"decorators/#example-usage_2","title":"Example Usage:","text":"<pre><code>from mockafka import consume\n\n@consume(topics=['test_topic'], auto_commit=False)\ndef test_function(message):\n    # Your test logic for processing the consumed message here\n    pass\n</code></pre>"},{"location":"decorators/#bulk_produce-decorator","title":"<code>@bulk_produce</code> Decorator","text":"<p>This decorator is for bulk-producing messages using a <code>FakeProducer</code>. It allows you to specify a list of dictionaries containing message details such as value, key, topic, partition, timestamp, and headers.</p>"},{"location":"decorators/#parameters_3","title":"Parameters:","text":"<ul> <li><code>list_of_messages (list[dict[str, str]])</code>: A list of dictionaries containing message details.</li> </ul>"},{"location":"decorators/#example-usage_3","title":"Example Usage:","text":"<pre><code>from mockafka import bulk_produce\n\n\n@bulk_produce(list_of_messages=[{'topic': 'test_topic', 'value': 'test_value1'}, {...}])\ndef test_function():\n    # Your test logic here\n    pass\n</code></pre> <p>Feel free to use these decorators in your test functions to set up, produce, consume, and bulk-produce messages in a Mockafka environment.</p>"},{"location":"decorators/#multi-decorator-examples-documentation","title":"Multi-Decorator Examples Documentation","text":"<p>In the following examples, we showcase the usage of multiple decorators to simulate different scenarios in a Mockafka environment. These scenarios include producing, consuming, and setting up Kafka topics using the provided decorators.</p>"},{"location":"decorators/#example-1-using-produce-and-consume-decorators","title":"Example 1: Using <code>@produce</code> and <code>@consume</code> Decorators","text":""},{"location":"decorators/#test-case-test_produce_decorator","title":"Test Case: <code>test_produce_decorator</code>","text":"<pre><code>from mockafka import produce, consume\n\n@produce(topic='test', key='test_key', value='test_value', partition=4)\n@consume(topics=['test'])\ndef test_produce_and_consume_decorator(message):\n    \"\"\"\n    This test showcases the usage of both @produce and @consume decorators in a single test case.\n    It produces a message to the 'test' topic and then consumes it to perform further logic.\n    # Notice you may got message None\n    \"\"\"\n    # Your test logic for processing the consumed message here\n\n    if not message:\n        return \n\n    pass\n</code></pre>"},{"location":"decorators/#example-2-using-multiple-produce-decorators","title":"Example 2: Using Multiple <code>@produce</code> Decorators","text":""},{"location":"decorators/#test-case-test_produce_twice","title":"Test Case: <code>test_produce_twice</code>","text":"<pre><code>from mockafka import produce\n\n@produce(topic='test', key='test_key', value='test_value', partition=4)\n@produce(topic='test', key='test_key1', value='test_value1', partition=0)\ndef test_produce_twice():\n    # Your test logic here\n    pass\n</code></pre>"},{"location":"decorators/#example-3-using-bulk_produce-and-consume-decorators","title":"Example 3: Using <code>@bulk_produce</code> and <code>@consume</code> Decorators","text":""},{"location":"decorators/#test-case-test_bulk_produce_decorator","title":"Test Case: <code>test_bulk_produce_decorator</code>","text":"<pre><code>from mockafka import bulk_produce, consume\n\n@bulk_produce(list_of_messages=sample_for_bulk_produce)\n@consume(topics=['test'])\ndef test_bulk_produce_and_consume_decorator(message):\n    \"\"\"\n    This test showcases the usage of both @bulk_produce and @consume decorators in a single test case.\n    It bulk produces messages to the 'test' topic and then consumes them to perform further logic.\n    \"\"\"\n    # Your test logic for processing the consumed message here\n    pass\n</code></pre>"},{"location":"decorators/#example-4-using-setup_kafka-and-produce-decorators","title":"Example 4: Using <code>@setup_kafka</code> and <code>@produce</code> Decorators","text":""},{"location":"decorators/#test-case-test_produce_with_kafka_setup_decorator","title":"Test Case: <code>test_produce_with_kafka_setup_decorator</code>","text":"<pre><code>from mockafka import setup_kafka, produce\n\n@setup_kafka(topics=[{\"topic\": \"test_topic\", \"partition\": 16}])\n@produce(topic='test_topic', partition=5, key='test_', value='test_value1')\ndef test_produce_with_kafka_setup_decorator():\n    # Your test logic here\n    pass\n</code></pre>"},{"location":"decorators/#example-5-using-setup_kafka-multiple-produce-and-consume-decorators","title":"Example 5: Using <code>@setup_kafka</code>, Multiple <code>@produce</code>, and <code>@consume</code> Decorators","text":""},{"location":"decorators/#test-case-test_consumer_decorator","title":"Test Case: <code>test_consumer_decorator</code>","text":"<pre><code>from mockafka import setup_kafka, produce, consume, Message\n\n@setup_kafka(topics=[{\"topic\": \"test_topic\", \"partition\": 16}])\n@produce(topic='test_topic', partition=5, key='test_', value='test_value1')\n@produce(topic='test_topic', partition=5, key='test_', value='test_value1')\n@consume(topics=['test_topic'])\ndef test_consumer_decorator(message: Message = None):\n    if message is None:\n        return\n    # Your test logic for processing the consumed message here\n    pass\n</code></pre>"},{"location":"fake-admin-client/","title":"fake admin client","text":""},{"location":"fake-admin-client/#fakeadminclientimpl-class","title":"FakeAdminClientImpl Class","text":""},{"location":"fake-admin-client/#description","title":"Description","text":"<p>The <code>FakeAdminClientImpl</code> class is a mock implementation of the Confluent Kafka AdminClient for testing purposes. It utilizes an in-memory storage (<code>KafkaStore</code>) to simulate Kafka behavior. This class includes methods for managing partitions, topics, and other administrative actions.</p>"},{"location":"fake-admin-client/#properties","title":"Properties","text":"<ul> <li>kafka: An instance of the <code>KafkaStore</code> class for in-memory storage.</li> <li>clean (bool): A flag indicating whether to start with a clean slate.</li> </ul>"},{"location":"fake-admin-client/#methods","title":"Methods","text":""},{"location":"fake-admin-client/#__init__self-clean-bool-true-args-kwargs","title":"<code>__init__(self, clean: bool = True, *args, **kwargs)</code>","text":"<ul> <li>Description: Initializes the <code>FakeAdminClientImpl</code>.</li> <li>Parameters:</li> <li><code>clean (bool)</code>: Flag indicating whether to start with a clean slate.</li> <li><code>args</code>: Additional arguments (unused).</li> <li><code>kwargs</code>: Additional keyword arguments (unused).</li> </ul>"},{"location":"fake-admin-client/#create_partitionsself-partitions-listnewpartitions","title":"<code>create_partitions(self, partitions: list[NewPartitions])</code>","text":"<ul> <li>Description: Creates partitions in the in-memory Kafka store.</li> <li>Parameters:</li> <li><code>partitions (List[NewPartitions])</code>: List of partition objects to be created.</li> </ul>"},{"location":"fake-admin-client/#create_partitionself-partition-newpartitions","title":"<code>create_partition(self, partition: NewPartitions)</code>","text":"<ul> <li>Description: Creates a single partition in the in-memory Kafka store.</li> <li>Parameters:</li> <li><code>partition (NewPartitions)</code>: The partition object to be created.</li> </ul>"},{"location":"fake-admin-client/#create_topicsself-topics-listnewtopic","title":"<code>create_topics(self, topics: list[NewTopic])</code>","text":"<ul> <li>Description: Creates topics in the in-memory Kafka store.</li> <li>Parameters:</li> <li><code>topics (List[NewTopic])</code>: List of topic objects to be created.</li> </ul>"},{"location":"fake-admin-client/#create_topicself-topic-newtopic","title":"<code>create_topic(self, topic: NewTopic)</code>","text":"<ul> <li>Description: Creates a single topic in the in-memory Kafka store.</li> <li>Parameters:</li> <li><code>topic (NewTopic)</code>: The topic object to be created.</li> </ul>"},{"location":"fake-admin-client/#delete_topicsself-topics-futurenone-request_timeoutnone-operation_timeoutnone","title":"<code>delete_topics(self, topics, future=None, request_timeout=None, operation_timeout=None)</code>","text":"<ul> <li>Description: Deletes topics from the in-memory Kafka store.</li> <li>Parameters:</li> <li><code>topics</code>: Topics to be deleted.</li> <li><code>future</code>: Unused parameter (for compatibility).</li> <li><code>request_timeout</code>: Unused parameter (for compatibility).</li> <li><code>operation_timeout</code>: Unused parameter (for compatibility).</li> </ul>"},{"location":"fake-admin-client/#delete_topicself-topic-newtopic","title":"<code>delete_topic(self, topic: NewTopic)</code>","text":"<ul> <li>Description: Deletes a single topic from the in-memory Kafka store.</li> <li>Parameters:</li> <li><code>topic (NewTopic)</code>: The topic object to be deleted.</li> </ul>"},{"location":"fake-admin-client/#describe_aclsself-acl_binding_filter-future-request_timeoutnone","title":"<code>describe_acls(self, acl_binding_filter, future, request_timeout=None)</code>","text":"<ul> <li>Description: Describes ACLs (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>acl_binding_filter</code>: Unused parameter (unsupported).</li> <li><code>future</code>: Unused parameter (unsupported).</li> <li><code>request_timeout</code>: Unused parameter (unsupported).</li> </ul>"},{"location":"fake-admin-client/#describe_configsself-resources-future-request_timeoutnone-brokernone","title":"<code>describe_configs(self, resources, future, request_timeout=None, broker=None)</code>","text":"<ul> <li>Description: Describes configurations (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>resources</code>: Unused parameter (unsupported).</li> <li><code>future</code>: Unused parameter (unsupported).</li> <li><code>request_timeout</code>: Unused parameter (unsupported).</li> <li><code>broker</code>: Unused parameter (unsupported).</li> </ul>"},{"location":"fake-admin-client/#delete_aclsself-acl_binding_filters-future-request_timeoutnone","title":"<code>delete_acls(self, acl_binding_filters, future, request_timeout=None)</code>","text":"<ul> <li>Description: Deletes ACLs (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>acl_binding_filters</code>: Unused parameter (unsupported).</li> <li><code>future</code>: Unused parameter (unsupported).</li> <li><code>request_timeout</code>: Unused parameter (unsupported).</li> </ul>"},{"location":"fake-admin-client/#alter_configsself-args-kwargs","title":"<code>alter_configs(self, *args, **kwargs)</code>","text":"<ul> <li>Description: Alters configurations (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>args</code>: Unused parameter (unsupported).</li> <li><code>kwargs</code>: Unused parameter (unsupported).</li> </ul>"},{"location":"fake-admin-client/#create_aclsself-args-kwargs","title":"<code>create_acls(self, *args, **kwargs)</code>","text":"<ul> <li>Description: Creates ACLs (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>args</code>: Unused parameter (unsupported).</li> <li><code>kwargs</code>: Unused parameter (unsupported).</li> </ul>"},{"location":"fake-admin-client/#list_groupsself-groupnone-args-kwargs","title":"<code>list_groups(self, group=None, *args, **kwargs)</code>","text":"<ul> <li>Description: Lists consumer groups (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>group</code>: Unused parameter (unsupported).</li> <li><code>args</code>: Unused parameter (unsupported).</li> <li><code>kwargs</code>: Unused parameter (unsupported).</li> </ul>"},{"location":"fake-admin-client/#list_topicsself-topicnone-args-kwargs-clustermetadata","title":"<code>list_topics(self, topic=None, *args, **kwargs) -&gt; ClusterMetadata</code>","text":"<ul> <li>Description: Lists topics and returns <code>ClusterMetadata</code>.</li> <li>Parameters:</li> <li><code>topic</code>: Unused parameter (for compatibility).</li> <li><code>args</code>: Unused parameter (for compatibility).</li> <li><code>kwargs</code>: Unused parameter (for compatibility).</li> <li>Returns: (ClusterMetadata) Metadata of the listed topics.</li> </ul>"},{"location":"fake-admin-client/#pollself-timeoutnone","title":"<code>poll(self, timeout=None)</code>","text":"<ul> <li>Description: Polls for events (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>timeout</code>: Unused parameter (unsupported).</li> </ul>"},{"location":"fake-admin-client/#__len__self-args-kwargs","title":"<code>__len__(self, *args, **kwargs)</code>","text":"<ul> <li>Description: Gets the length of the Kafka store (not implemented).</li> <li>Parameters:</li> <li><code>args</code>: Unused parameters (not implemented).</li> <li><code>kwargs</code>: Unused parameters (not implemented).</li> </ul>"},{"location":"fake-admin-client/#example-usage","title":"Example Usage","text":"<pre><code>from mockafka.admin_client import FakeAdminClientImpl, NewTopic, NewPartitions\n\n# Create an instance of FakeAdminClientImpl\nfake_admin_client = FakeAdminClientImpl()\n\n# Create a topic with partitions\nfake_admin_client.create_topic(topic=NewTopic(topic='sample_topic', num_partitions=3))\n\n# Delete a topic\nfake_admin_client.delete_topic(topic=NewTopic(topic='sample_topic', num_partitions=3))\n\n# List topics\ntopics_metadata = fake_admin_client.list_topics()\n\n# Create partitions for a topic\nfake_admin_client.create_partitions(partitions=[NewPartitions(topic='sample_topic', new_total_count=5)])\n</code></pre>"},{"location":"fake-consumer/","title":"fake consumer","text":""},{"location":"fake-consumer/#fakeconsumer-class","title":"FakeConsumer Class","text":""},{"location":"fake-consumer/#description","title":"Description","text":"<p>The <code>FakeConsumer</code> class is a mock implementation of the Confluent Kafka Consumer designed for testing purposes. It uses an in-memory storage (<code>KafkaStore</code>) to simulate Kafka behavior. The class includes methods for consuming, committing, listing topics, polling for messages, and managing subscriptions.</p>"},{"location":"fake-consumer/#properties","title":"Properties","text":"<ul> <li>kafka: An instance of the <code>KafkaStore</code> class for in-memory storage.</li> <li>consumer_store: A dictionary to store consumer offsets for each topic-partition.</li> <li>subscribed_topic: A list of topics subscribed by the consumer.</li> </ul>"},{"location":"fake-consumer/#methods","title":"Methods","text":""},{"location":"fake-consumer/#__init__self-args-kwargs","title":"<code>__init__(self, *args, **kwargs)</code>","text":"<ul> <li>Description: Initializes the <code>FakeConsumer</code>.</li> <li>Parameters:</li> <li><code>args</code>: Additional arguments (unused).</li> <li><code>kwargs</code>: Additional keyword arguments (unused).</li> </ul>"},{"location":"fake-consumer/#consumeself-num_messages1-args-kwargs-message-or-none","title":"<code>consume(self, num_messages=1, *args, **kwargs) -&gt; Message or None</code>","text":"<ul> <li>Description: Consumes messages from subscribed topics.</li> <li>Parameters:</li> <li><code>num_messages</code> (int): Number of messages to consume.</li> <li><code>args</code>: Additional arguments (unused).</li> <li><code>kwargs</code>: Additional keyword arguments (unused).</li> <li>Returns: (Message or None) Consumed message or None if no message is available.</li> </ul>"},{"location":"fake-consumer/#closeself-args-kwargs","title":"<code>close(self, *args, **kwargs)</code>","text":"<ul> <li>Description: Closes the consumer and resets state.</li> <li>Parameters:</li> <li><code>args</code>: Additional arguments (unused).</li> <li><code>kwargs</code>: Additional keyword arguments (unused).</li> </ul>"},{"location":"fake-consumer/#commitself-message-message-none-args-kwargs","title":"<code>commit(self, message: Message = None, *args, **kwargs)</code>","text":"<ul> <li>Description: Commits offsets for consumed messages.</li> <li>Parameters:</li> <li><code>message</code> (Message): Consumed message (unused).</li> <li><code>args</code>: Additional arguments (unused).</li> <li><code>kwargs</code>: Additional keyword arguments (unused).</li> </ul>"},{"location":"fake-consumer/#list_topicsself-topicnone-args-kwargs-clustermetadata","title":"<code>list_topics(self, topic=None, *args, **kwargs) -&gt; ClusterMetadata</code>","text":"<ul> <li>Description: Lists topics and returns <code>ClusterMetadata</code>.</li> <li>Parameters:</li> <li><code>topic</code>: Topic name (unused).</li> <li><code>args</code>: Additional arguments (unused).</li> <li><code>kwargs</code>: Additional keyword arguments (unused).</li> <li>Returns: (ClusterMetadata) Metadata of the listed topics.</li> </ul>"},{"location":"fake-consumer/#pollself-timeoutnone-message-or-none","title":"<code>poll(self, timeout=None) -&gt; Message or None</code>","text":"<ul> <li>Description: Polls for messages from subscribed topics.</li> <li>Parameters:</li> <li><code>timeout</code> (float): Poll timeout in seconds.</li> <li>Returns: (Message or None) Consumed message or None if no message is available.</li> </ul>"},{"location":"fake-consumer/#_get_keyself-topic-partition-str","title":"<code>_get_key(self, topic, partition) -&gt; str</code>","text":"<ul> <li>Description: Generates a unique key for a topic-partition pair.</li> <li>Parameters:</li> <li><code>topic</code>: Topic name.</li> <li><code>partition</code>: Partition number.</li> <li>Returns: (str) Unique key for the topic-partition pair.</li> </ul>"},{"location":"fake-consumer/#subscribeself-topics-on_assignnone-args-kwargs","title":"<code>subscribe(self, topics, on_assign=None, *args, **kwargs)</code>","text":"<ul> <li>Description: Subscribes to one or more topics.</li> <li>Parameters:</li> <li><code>topics</code> (list): List of topics to subscribe to.</li> <li><code>on_assign</code>: Callback function for partition assignments (unused).</li> <li><code>args</code>: Additional arguments (unused).</li> <li><code>kwargs</code>: Additional keyword arguments (unused).</li> <li>Raises: (KafkaException) If a subscribed topic does not exist in the Kafka store.</li> </ul>"},{"location":"fake-consumer/#unsubscribeself-args-kwargs","title":"<code>unsubscribe(self, *args, **kwargs)</code>","text":"<ul> <li>Description: Unsubscribes from one or more topics.</li> <li>Parameters:</li> <li><code>args</code>: Additional arguments (unused).</li> <li><code>kwargs</code>: Additional keyword arguments.</li> </ul>"},{"location":"fake-consumer/#assignself-partitions","title":"<code>assign(self, partitions)</code>","text":"<ul> <li>Description: Assigns partitions to the consumer (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>partitions</code>: Partitions to assign (unused).</li> </ul>"},{"location":"fake-consumer/#unassignself-args-kwargs","title":"<code>unassign(self, *args, **kwargs)</code>","text":"<ul> <li>Description: Unassigns partitions (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>args</code>: Additional arguments (unused).</li> <li><code>kwargs</code>: Additional keyword arguments (unused).</li> </ul>"},{"location":"fake-consumer/#assignmentself-args-kwargs-list","title":"<code>assignment(self, *args, **kwargs) -&gt; list</code>","text":"<ul> <li>Description: Gets assigned partitions (unsupported in mockafka).</li> <li>Returns: (list) An empty list.</li> </ul>"},{"location":"fake-consumer/#committedself-partitions-timeoutnone-list","title":"<code>committed(self, partitions, timeout=None) -&gt; list</code>","text":"<ul> <li>Description: Gets committed offsets (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>partitions</code>: Partitions to get committed offsets for (unused).</li> <li><code>timeout</code>: Timeout for the operation (unused).</li> <li>Returns: (list) An empty list.</li> </ul>"},{"location":"fake-consumer/#get_watermark_offsetsself-partition-timeoutnone-args-kwargs-tuple","title":"<code>get_watermark_offsets(self, partition, timeout=None, *args, **kwargs) -&gt; tuple</code>","text":"<ul> <li>Description: Gets watermark offsets (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>partition</code>: Partition to get watermark offsets for (unused).</li> <li><code>timeout</code>: Timeout for the operation (unused).</li> <li><code>args</code>: Additional arguments (unused).</li> <li><code>kwargs</code>: Additional keyword arguments (unused).</li> <li>Returns: (tuple) Tuple with watermark offsets (0, 0).</li> </ul>"},{"location":"fake-consumer/#offsets_for_timesself-partitions-timeoutnone-list","title":"<code>offsets_for_times(self, partitions, timeout=None) -&gt; list</code>","text":"<ul> <li>Description: Gets offsets for given times (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>partitions</code>: Partitions to get offsets for (unused).</li> <li><code>timeout</code>: Timeout for the operation (unused).</li> <li>Returns: (list) An empty list.</li> </ul>"},{"location":"fake-consumer/#pauseself-partitions-none","title":"<code>pause(self, partitions) -&gt; None</code>","text":"<ul> <li>Description: Pauses consumption from specified partitions (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>partitions</code>: Partitions to pause consumption from (unused).</li> <li>Returns: (None)</li> </ul>"},{"location":"fake-consumer/#positionself-partitions-list","title":"<code>position(self, partitions) -&gt; list</code>","text":"<ul> <li>Description: Gets the current position of the consumer in specified partitions (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>partitions</code>: Partitions to get position for (unused).</li> <li>Returns: (list) An empty list.</li> </ul>"},{"location":"fake-consumer/#resumeself-partitions-none","title":"<code>resume(self, partitions) -&gt; None</code>","text":"<ul> <li>Description: Resumes consumption from specified partitions (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>partitions</code>: Partitions to resume consumption from (unused).</li> <li>Returns: (None)</li> </ul>"},{"location":"fake-consumer/#seekself-partition-none","title":"<code>seek(self, partition) -&gt; None</code>","text":"<ul> <li>Description: Seeks to a specific offset in a partition (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>partition</code>: Partition to seek in (unused).</li> </ul>"},{"location":"fake-consumer/#store_offsetsself-messagenone-args-kwargs-none","title":"<code>store_offsets(self, message=None, *args, **kwargs) -&gt; None</code>","text":"<ul> <li>Description: Stores offsets for consumed messages (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>message</code>: Consumed message (unused).</li> <li><code>args</code>: Additional arguments (unused).</li> <li><code>kwargs</code>: Additional keyword arguments (unused).</li> <li>Returns: (None)</li> </ul>"},{"location":"fake-consumer/#consumer_group_metadataself-none","title":"<code>consumer_group_metadata(self) -&gt; None</code>","text":"<ul> <li>Description: Gets consumer group metadata (unsupported in mockafka).</li> <li>Returns: (None)</li> </ul>"},{"location":"fake-consumer/#incremental_assignself-partitions-none","title":"<code>incremental_assign(self, partitions) -&gt; None</code>","text":"<ul> <li>Description: Incrementally assigns partitions (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>partitions</code>: Partitions to incrementally assign (unused).</li> <li>Returns: (None)</li> </ul>"},{"location":"fake-consumer/#incremental_unassignself-partitions-none","title":"<code>incremental_unassign(self, partitions) -&gt; None</code>","text":"<ul> <li>Description: Incrementally unassigns partitions (unsupported in mockafka).</li> <li>Parameters:   -</li> </ul> <p><code>partitions</code>: Partitions to incrementally unassign (unused). - Returns: (None)</p>"},{"location":"fake-consumer/#example-usage","title":"Example Usage","text":"<pre><code>from mockafka import FakeConsumer\n\n# Create an instance of FakeConsumer\nfake_consumer = FakeConsumer()\n\n# Subscribe to topics\nfake_consumer.subscribe(topics=['sample_topic'])\n\n# Consume messages\nconsumed_message = fake_consumer.consume()\n\n# Commit offsets\nfake_consumer.commit()\n\n# Unsubscribe from topics\nfake_consumer.unsubscribe(topics=['sample_topic'])\n\n# Close the consumer\nfake_consumer.close()\n</code></pre>"},{"location":"fake-produce/","title":"fake producer","text":""},{"location":"fake-produce/#fakeproducer-class","title":"FakeProducer Class","text":""},{"location":"fake-produce/#description","title":"Description","text":"<p>The <code>FakeProducer</code> class is a mock implementation of the Confluent Kafka Producer for testing purposes. It uses an in-memory storage (<code>KafkaStore</code>) to simulate Kafka behavior. The class includes methods for producing messages, listing topics, and handling transactions.</p>"},{"location":"fake-produce/#properties","title":"Properties","text":"<ul> <li>kafka: An instance of the <code>KafkaStore</code> class for in-memory storage.</li> </ul>"},{"location":"fake-produce/#methods","title":"Methods","text":""},{"location":"fake-produce/#__init__self-config-dict-none","title":"<code>__init__(self, config: dict = None)</code>","text":"<ul> <li>Description: Initializes the <code>FakeProducer</code>.</li> <li>Parameters:</li> <li><code>config</code> (dict): Configuration for the producer (unused).</li> </ul>"},{"location":"fake-produce/#produceself-topic-valuenone-args-kwargs","title":"<code>produce(self, topic, value=None, *args, **kwargs)</code>","text":"<ul> <li>Description: Produces messages to a specified topic.</li> <li>Parameters:</li> <li><code>topic</code>: Topic to produce messages to.</li> <li><code>value</code>: Message value (unused).</li> <li><code>args</code>: Additional arguments (unused).</li> <li><code>kwargs</code>: Additional keyword arguments, including the partition for the message.</li> </ul>"},{"location":"fake-produce/#list_topicsself-topicnone-args-kwargs-clustermetadata","title":"<code>list_topics(self, topic=None, *args, **kwargs) -&gt; ClusterMetadata</code>","text":"<ul> <li>Description: Lists topics and returns <code>ClusterMetadata</code>.</li> <li>Parameters:</li> <li><code>topic</code>: Topic name (unused).</li> <li><code>args</code>: Additional arguments (unused).</li> <li><code>kwargs</code>: Additional keyword arguments (unused).</li> <li>Returns: (ClusterMetadata) Metadata of the listed topics.</li> </ul>"},{"location":"fake-produce/#abort_transactionself-timeoutnone","title":"<code>abort_transaction(self, timeout=None)</code>","text":"<ul> <li>Description: Aborts a transaction (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>timeout</code>: Timeout for the operation (unused).</li> </ul>"},{"location":"fake-produce/#begin_transactionself","title":"<code>begin_transaction(self)</code>","text":"<ul> <li>Description: Begins a transaction (unsupported in mockafka).</li> </ul>"},{"location":"fake-produce/#commit_transactionself-timeoutnone","title":"<code>commit_transaction(self, timeout=None)</code>","text":"<ul> <li>Description: Commits a transaction (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>timeout</code>: Timeout for the operation (unused).</li> </ul>"},{"location":"fake-produce/#flushself-timeoutnone-int","title":"<code>flush(self, timeout=None) -&gt; int</code>","text":"<ul> <li>Description: Flushes the producer (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>timeout</code>: Timeout for the operation (unused).</li> <li>Returns: (int) Always returns 0.</li> </ul>"},{"location":"fake-produce/#init_transactionsself-timeoutnone","title":"<code>init_transactions(self, timeout=None)</code>","text":"<ul> <li>Description: Initializes transactions (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>timeout</code>: Timeout for the operation (unused).</li> </ul>"},{"location":"fake-produce/#pollself-timeoutnone-int","title":"<code>poll(self, timeout=None) -&gt; int</code>","text":"<ul> <li>Description: Polls for events (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>timeout</code>: Timeout for the operation (unused).</li> <li>Returns: (int) Always returns 0.</li> </ul>"},{"location":"fake-produce/#purgeself-in_queuetrue-args-kwargs","title":"<code>purge(self, in_queue=True, *args, **kwargs)</code>","text":"<ul> <li>Description: Purges messages (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>in_queue</code>: Purge messages in the queue (unused).</li> <li><code>args</code>: Additional arguments (unused).</li> <li><code>kwargs</code>: Additional keyword arguments (unused).</li> </ul>"},{"location":"fake-produce/#send_offsets_to_transactionself-positions-group_metadata-timeoutnone","title":"<code>send_offsets_to_transaction(self, positions, group_metadata, timeout=None)</code>","text":"<ul> <li>Description: Sends offsets to a transaction (unsupported in mockafka).</li> <li>Parameters:</li> <li><code>positions</code>: Offset positions (unused).</li> <li><code>group_metadata</code>: Group metadata (unused).</li> <li><code>timeout</code>: Timeout for the operation (unused).</li> </ul>"},{"location":"fake-produce/#example-usage","title":"Example Usage","text":"<pre><code>from mockafka import FakeProducer\n\n# Create an instance of FakeProducer\nfake_producer = FakeProducer()\n\n# Produce a message\nfake_producer.produce(topic='sample_topic', value='Hello, Kafka!', partition=0)\n</code></pre>"},{"location":"kafka-store/","title":"kafka store","text":""},{"location":"kafka-store/#kafkastore-class","title":"KafkaStore Class","text":""},{"location":"kafka-store/#description","title":"Description","text":"<p>The <code>KafkaStore</code> class represents an in-memory simulation of a Kafka store. It includes methods for managing topics, partitions, offsets, and producing/consuming messages.</p>"},{"location":"kafka-store/#properties","title":"Properties","text":"<ul> <li>mock_topics: A dictionary to store topics, each containing partitions and associated messages.</li> <li>offset_store: A dictionary to store offset information for each topic and partition.</li> </ul>"},{"location":"kafka-store/#methods","title":"Methods","text":""},{"location":"kafka-store/#__init__self-clean-bool-false","title":"<code>__init__(self, clean: bool = False)</code>","text":"<ul> <li>Description: Initializes the KafkaStore.</li> <li>Parameters:</li> <li><code>clean</code> (bool): If True, clears existing mock topics and offset store.</li> </ul>"},{"location":"kafka-store/#is_topic_existtopic-str-bool","title":"<code>is_topic_exist(topic: str) -&gt; bool</code>","text":"<ul> <li>Description: Checks if a topic exists.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> <li>Returns: (bool) True if the topic exists, False otherwise.</li> </ul>"},{"location":"kafka-store/#is_partition_exist_on_topictopic-str-partition_num-int-bool","title":"<code>is_partition_exist_on_topic(topic: str, partition_num: int) -&gt; bool</code>","text":"<ul> <li>Description: Checks if a partition exists in a given topic.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> <li><code>partition_num</code> (int): The partition number.</li> <li>Returns: (bool) True if the partition exists, False otherwise.</li> </ul>"},{"location":"kafka-store/#get_number_of_partitiontopic-str-int","title":"<code>get_number_of_partition(topic: str) -&gt; int</code>","text":"<ul> <li>Description: Gets the number of partitions in a topic.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> <li>Returns: (int) The number of partitions in the topic.</li> </ul>"},{"location":"kafka-store/#create_topictopic-str","title":"<code>create_topic(topic: str)</code>","text":"<ul> <li>Description: Creates a new topic.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> </ul>"},{"location":"kafka-store/#create_partitionself-topic-str-partitions-int","title":"<code>create_partition(self, topic: str, partitions: int)</code>","text":"<ul> <li>Description: Creates partitions for a topic.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> <li><code>partitions</code> (int): The number of partitions to create.</li> </ul>"},{"location":"kafka-store/#remove_topicself-topic-str","title":"<code>remove_topic(self, topic: str)</code>","text":"<ul> <li>Description: Removes a topic and its associated partitions.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> </ul>"},{"location":"kafka-store/#set_first_offsetself-topic-str-partition-int-value-int","title":"<code>set_first_offset(self, topic: str, partition: int, value: int)</code>","text":"<ul> <li>Description: Sets the first offset for a partition.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> <li><code>partition</code> (int): The partition number.</li> <li><code>value</code> (int): The offset value.</li> </ul>"},{"location":"kafka-store/#_add_next_offsetself-topic-str-partition-int","title":"<code>_add_next_offset(self, topic: str, partition: int)</code>","text":"<ul> <li>Description: Increments the next offset for a partition.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> <li><code>partition</code> (int): The partition number.</li> </ul>"},{"location":"kafka-store/#get_offset_store_keyself-topic-str-partition-int-str","title":"<code>get_offset_store_key(self, topic: str, partition: int) -&gt; str</code>","text":"<ul> <li>Description: Generates the key for offset storage.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> <li><code>partition</code> (int): The partition number.</li> <li>Returns: (str) Offset store key.</li> </ul>"},{"location":"kafka-store/#produceself-message-message-topic-str-partition-int","title":"<code>produce(self, message: Message, topic: str, partition: int)</code>","text":"<ul> <li>Description: Produces a message to a specific topic and partition.</li> <li>Parameters:</li> <li><code>message</code> (Message): The message to produce.</li> <li><code>topic</code> (str): The name of the topic.</li> <li><code>partition</code> (int): The partition number.</li> </ul>"},{"location":"kafka-store/#get_messageself-topic-str-partition-int-offset-int-message","title":"<code>get_message(self, topic: str, partition: int, offset: int) -&gt; Message</code>","text":"<ul> <li>Description: Gets a message from a specific topic, partition, and offset.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> <li><code>partition</code> (int): The partition number.</li> <li><code>offset</code> (int): The offset of the message.</li> <li>Returns: (Message) The requested message.</li> </ul>"},{"location":"kafka-store/#get_partition_first_offsetself-topic-str-partition-int-int","title":"<code>get_partition_first_offset(self, topic: str, partition: int) -&gt; int</code>","text":"<ul> <li>Description: Gets the first offset for a partition.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> <li><code>partition</code> (int): The partition number.</li> <li>Returns: (int) The first offset for the partition.</li> </ul>"},{"location":"kafka-store/#get_partition_next_offsetself-topic-str-partition-int-int","title":"<code>get_partition_next_offset(self, topic: str, partition: int) -&gt; int</code>","text":"<ul> <li>Description: Gets the next offset for a partition.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> <li><code>partition</code> (int): The partition number.</li> <li>Returns: (int) The next offset for the partition.</li> </ul>"},{"location":"kafka-store/#topic_list-liststr","title":"<code>topic_list() -&gt; list[str]</code>","text":"<ul> <li>Description: Gets the list of existing topics.</li> <li>Returns: (list[str]) List of topic names.</li> </ul>"},{"location":"kafka-store/#partition_listtopic-str-listint","title":"<code>partition_list(topic: str) -&gt; list[int]</code>","text":"<ul> <li>Description: Gets the list of partitions for a given topic.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> <li>Returns: (list[int]) List of partition numbers.</li> </ul>"},{"location":"kafka-store/#get_messages_in_partitiontopic-str-partition-int-listmessage","title":"<code>get_messages_in_partition(topic: str, partition: int) -&gt; list[Message]</code>","text":"<ul> <li>Description: Gets all messages in a specific partition.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> <li><code>partition</code> (int): The partition number.</li> <li>Returns: (list[Message]) List of messages in the partition.</li> </ul>"},{"location":"kafka-store/#number_of_message_in_topicself-topic-str-int","title":"<code>number_of_message_in_topic(self, topic: str) -&gt; int</code>","text":"<ul> <li>Description: Gets the total number of messages in a topic.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> <li>Returns: (int) The total number of messages in the topic.</li> </ul>"},{"location":"kafka-store/#clear_topic_messagesself-topic-str","title":"<code>clear_topic_messages(self, topic: str)</code>","text":"<ul> <li>Description: Clears all messages in a topic.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> </ul>"},{"location":"kafka-store/#clear_partition_messagestopic-str-partition-int","title":"<code>clear_partition_messages(topic: str, partition: int)</code>","text":"<ul> <li>Description: Clears all messages in a specific partition.</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> <li><code>partition</code> (int): The partition number.</li> </ul>"},{"location":"kafka-store/#reset_offsetself-topic-str-strategy-str-latest","title":"<code>reset_offset(self, topic: str, strategy: str = 'latest')</code>","text":"<ul> <li>Description: Resets offsets for a topic based on a strategy (latest or earliest).</li> <li>Parameters:</li> <li><code>topic</code> (str): The name of the topic.</li> <li><code>strategy</code> (str): The offset reset strategy ('latest' or 'earliest').</li> </ul>"},{"location":"kafka-store/#fresh","title":"<code>fresh()</code>","text":"<ul> <li>Description: Clears all mock topics and offset stores, essentially starting fresh.</li> </ul>"},{"location":"kafka-store/#example-usage","title":"Example Usage","text":"<pre><code>from mockafka.kafka_store import KafkaStore\nfrom mockafka.message import Message\n\n# Create an instance of KafkaStore\nkafka_store = KafkaStore()\n\n# Create a topic and partitions\nkafka_store.create_topic('sample_topic')\nkafka_store.create_partition('sample_topic', 4)\n\n# Produce a message to a specific partition\nmessage = Message(content='Hello, Kafka!')\nkafka_store.produce(message, 'sample_topic', 1)\n\n# Get a message from a specific topic, partition, and offset\nretrieved_message = kafka_store.get_message('sample_topic', 1, 0)\n</code></pre>"}]}